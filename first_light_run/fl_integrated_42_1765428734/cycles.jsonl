{"cycle": 0, "candidates_processed": 7, "proofs_verified": 5, "abstentions": 2, "abstention_rate": 0.2857142857142857, "policy_weights": {"len": -0.010000000000000002, "depth": 0.005000000000000001, "success": 0.1}}
{"cycle": 1, "candidates_processed": 8, "proofs_verified": 6, "abstentions": 2, "abstention_rate": 0.25, "policy_weights": {"len": -0.030000000000000006, "depth": 0.015000000000000003, "success": 0.30000000000000004}}
{"cycle": 2, "candidates_processed": 9, "proofs_verified": 7, "abstentions": 2, "abstention_rate": 0.2222222222222222, "policy_weights": {"len": -0.06000000000000001, "depth": 0.030000000000000006, "success": 0.6000000000000001}}
{"cycle": 3, "candidates_processed": 10, "proofs_verified": 3, "abstentions": 7, "abstention_rate": 0.7, "policy_weights": {"len": -0.05000000000000001, "depth": 0.025000000000000005, "success": 0.5900000000000001}}
{"cycle": 4, "candidates_processed": 11, "proofs_verified": 4, "abstentions": 7, "abstention_rate": 0.6363636363636364, "policy_weights": {"len": -0.05010000000000001, "depth": 0.025050000000000006, "success": 0.5950000000000001}}
{"cycle": 5, "candidates_processed": 12, "proofs_verified": 5, "abstentions": 7, "abstention_rate": 0.5833333333333334, "policy_weights": {"len": -0.060100000000000015, "depth": 0.030050000000000007, "success": 0.6950000000000001}}
{"cycle": 6, "candidates_processed": 13, "proofs_verified": 6, "abstentions": 7, "abstention_rate": 0.5384615384615384, "policy_weights": {"len": -0.08010000000000002, "depth": 0.04005000000000001, "success": 0.895}}
{"cycle": 7, "candidates_processed": 14, "proofs_verified": 7, "abstentions": 7, "abstention_rate": 0.5, "policy_weights": {"len": -0.11010000000000003, "depth": 0.055050000000000016, "success": 1.195}}
{"cycle": 8, "candidates_processed": 5, "proofs_verified": 3, "abstentions": 2, "abstention_rate": 0.4, "policy_weights": {"len": -0.10010000000000002, "depth": 0.05005000000000001, "success": 1.185}}
{"cycle": 9, "candidates_processed": 6, "proofs_verified": 4, "abstentions": 2, "abstention_rate": 0.3333333333333333, "policy_weights": {"len": -0.10020000000000003, "depth": 0.05010000000000001, "success": 1.19}}
{"cycle": 10, "candidates_processed": 7, "proofs_verified": 5, "abstentions": 2, "abstention_rate": 0.2857142857142857, "policy_weights": {"len": -0.11020000000000002, "depth": 0.05510000000000001, "success": 1.29}}
{"cycle": 11, "candidates_processed": 8, "proofs_verified": 6, "abstentions": 2, "abstention_rate": 0.25, "policy_weights": {"len": -0.13020000000000004, "depth": 0.06510000000000002, "success": 1.49}}
{"cycle": 12, "candidates_processed": 9, "proofs_verified": 7, "abstentions": 2, "abstention_rate": 0.2222222222222222, "policy_weights": {"len": -0.16020000000000004, "depth": 0.08010000000000002, "success": 1.79}}
{"cycle": 13, "candidates_processed": 10, "proofs_verified": 3, "abstentions": 7, "abstention_rate": 0.7, "policy_weights": {"len": -0.15020000000000003, "depth": 0.07510000000000001, "success": 1.78}}
{"cycle": 14, "candidates_processed": 11, "proofs_verified": 4, "abstentions": 7, "abstention_rate": 0.6363636363636364, "policy_weights": {"len": -0.15030000000000002, "depth": 0.07515000000000001, "success": 1.785}}
{"cycle": 15, "candidates_processed": 12, "proofs_verified": 5, "abstentions": 7, "abstention_rate": 0.5833333333333334, "policy_weights": {"len": -0.16030000000000003, "depth": 0.08015000000000001, "success": 1.885}}
{"cycle": 16, "candidates_processed": 13, "proofs_verified": 6, "abstentions": 7, "abstention_rate": 0.5384615384615384, "policy_weights": {"len": -0.18030000000000002, "depth": 0.09015000000000001, "success": 2.085}}
{"cycle": 17, "candidates_processed": 14, "proofs_verified": 7, "abstentions": 7, "abstention_rate": 0.5, "policy_weights": {"len": -0.21030000000000001, "depth": 0.10515000000000001, "success": 2.385}}
{"cycle": 18, "candidates_processed": 5, "proofs_verified": 3, "abstentions": 2, "abstention_rate": 0.4, "policy_weights": {"len": -0.2003, "depth": 0.10015, "success": 2.375}}
{"cycle": 19, "candidates_processed": 6, "proofs_verified": 4, "abstentions": 2, "abstention_rate": 0.3333333333333333, "policy_weights": {"len": -0.2004, "depth": 0.1002, "success": 2.38}}
{"cycle": 20, "candidates_processed": 7, "proofs_verified": 5, "abstentions": 2, "abstention_rate": 0.2857142857142857, "policy_weights": {"len": -0.2104, "depth": 0.1052, "success": 2.48}}
{"cycle": 21, "candidates_processed": 8, "proofs_verified": 6, "abstentions": 2, "abstention_rate": 0.25, "policy_weights": {"len": -0.2304, "depth": 0.1152, "success": 2.68}}
{"cycle": 22, "candidates_processed": 9, "proofs_verified": 7, "abstentions": 2, "abstention_rate": 0.2222222222222222, "policy_weights": {"len": -0.2604, "depth": 0.1302, "success": 2.9800000000000004}}
{"cycle": 23, "candidates_processed": 10, "proofs_verified": 3, "abstentions": 7, "abstention_rate": 0.7, "policy_weights": {"len": -0.2504, "depth": 0.1252, "success": 2.9700000000000006}}
{"cycle": 24, "candidates_processed": 11, "proofs_verified": 4, "abstentions": 7, "abstention_rate": 0.6363636363636364, "policy_weights": {"len": -0.2505, "depth": 0.12525, "success": 2.9750000000000005}}
{"cycle": 25, "candidates_processed": 12, "proofs_verified": 5, "abstentions": 7, "abstention_rate": 0.5833333333333334, "policy_weights": {"len": -0.2605, "depth": 0.13025, "success": 3.0750000000000006}}
{"cycle": 26, "candidates_processed": 13, "proofs_verified": 6, "abstentions": 7, "abstention_rate": 0.5384615384615384, "policy_weights": {"len": -0.2805, "depth": 0.14025, "success": 3.275000000000001}}
{"cycle": 27, "candidates_processed": 14, "proofs_verified": 7, "abstentions": 7, "abstention_rate": 0.5, "policy_weights": {"len": -0.31050000000000005, "depth": 0.15525000000000003, "success": 3.575000000000001}}
{"cycle": 28, "candidates_processed": 5, "proofs_verified": 3, "abstentions": 2, "abstention_rate": 0.4, "policy_weights": {"len": -0.30050000000000004, "depth": 0.15025000000000002, "success": 3.5650000000000013}}
{"cycle": 29, "candidates_processed": 6, "proofs_verified": 4, "abstentions": 2, "abstention_rate": 0.3333333333333333, "policy_weights": {"len": -0.30060000000000003, "depth": 0.15030000000000002, "success": 3.570000000000001}}
{"cycle": 30, "candidates_processed": 7, "proofs_verified": 5, "abstentions": 2, "abstention_rate": 0.2857142857142857, "policy_weights": {"len": -0.31060000000000004, "depth": 0.15530000000000002, "success": 3.6700000000000013}}
{"cycle": 31, "candidates_processed": 8, "proofs_verified": 6, "abstentions": 2, "abstention_rate": 0.25, "policy_weights": {"len": -0.33060000000000006, "depth": 0.16530000000000003, "success": 3.8700000000000014}}
{"cycle": 32, "candidates_processed": 9, "proofs_verified": 7, "abstentions": 2, "abstention_rate": 0.2222222222222222, "policy_weights": {"len": -0.3606000000000001, "depth": 0.18030000000000004, "success": 4.170000000000002}}
{"cycle": 33, "candidates_processed": 10, "proofs_verified": 3, "abstentions": 7, "abstention_rate": 0.7, "policy_weights": {"len": -0.3506000000000001, "depth": 0.17530000000000004, "success": 4.160000000000002}}
{"cycle": 34, "candidates_processed": 11, "proofs_verified": 4, "abstentions": 7, "abstention_rate": 0.6363636363636364, "policy_weights": {"len": -0.35070000000000007, "depth": 0.17535000000000003, "success": 4.165000000000002}}
{"cycle": 35, "candidates_processed": 12, "proofs_verified": 5, "abstentions": 7, "abstention_rate": 0.5833333333333334, "policy_weights": {"len": -0.3607000000000001, "depth": 0.18035000000000004, "success": 4.2650000000000015}}
{"cycle": 36, "candidates_processed": 13, "proofs_verified": 6, "abstentions": 7, "abstention_rate": 0.5384615384615384, "policy_weights": {"len": -0.3807000000000001, "depth": 0.19035000000000005, "success": 4.465000000000002}}
{"cycle": 37, "candidates_processed": 14, "proofs_verified": 7, "abstentions": 7, "abstention_rate": 0.5, "policy_weights": {"len": -0.4107000000000001, "depth": 0.20535000000000006, "success": 4.7650000000000015}}
{"cycle": 38, "candidates_processed": 5, "proofs_verified": 3, "abstentions": 2, "abstention_rate": 0.4, "policy_weights": {"len": -0.4007000000000001, "depth": 0.20035000000000006, "success": 4.755000000000002}}
{"cycle": 39, "candidates_processed": 6, "proofs_verified": 4, "abstentions": 2, "abstention_rate": 0.3333333333333333, "policy_weights": {"len": -0.4008000000000001, "depth": 0.20040000000000005, "success": 4.760000000000002}}
{"cycle": 40, "candidates_processed": 7, "proofs_verified": 5, "abstentions": 2, "abstention_rate": 0.2857142857142857, "policy_weights": {"len": -0.4108000000000001, "depth": 0.20540000000000005, "success": 4.860000000000001}}
{"cycle": 41, "candidates_processed": 8, "proofs_verified": 6, "abstentions": 2, "abstention_rate": 0.25, "policy_weights": {"len": -0.4308000000000001, "depth": 0.21540000000000006, "success": 5.060000000000001}}
{"cycle": 42, "candidates_processed": 9, "proofs_verified": 7, "abstentions": 2, "abstention_rate": 0.2222222222222222, "policy_weights": {"len": -0.46080000000000015, "depth": 0.23040000000000008, "success": 5.360000000000001}}
{"cycle": 43, "candidates_processed": 10, "proofs_verified": 3, "abstentions": 7, "abstention_rate": 0.7, "policy_weights": {"len": -0.45080000000000015, "depth": 0.22540000000000007, "success": 5.350000000000001}}
{"cycle": 44, "candidates_processed": 11, "proofs_verified": 4, "abstentions": 7, "abstention_rate": 0.6363636363636364, "policy_weights": {"len": -0.45090000000000013, "depth": 0.22545000000000007, "success": 5.355000000000001}}
{"cycle": 45, "candidates_processed": 12, "proofs_verified": 5, "abstentions": 7, "abstention_rate": 0.5833333333333334, "policy_weights": {"len": -0.46090000000000014, "depth": 0.23045000000000007, "success": 5.455000000000001}}
{"cycle": 46, "candidates_processed": 13, "proofs_verified": 6, "abstentions": 7, "abstention_rate": 0.5384615384615384, "policy_weights": {"len": -0.48090000000000016, "depth": 0.24045000000000008, "success": 5.655000000000001}}
{"cycle": 47, "candidates_processed": 14, "proofs_verified": 7, "abstentions": 7, "abstention_rate": 0.5, "policy_weights": {"len": -0.5109000000000001, "depth": 0.25545000000000007, "success": 5.955000000000001}}
{"cycle": 48, "candidates_processed": 5, "proofs_verified": 3, "abstentions": 2, "abstention_rate": 0.4, "policy_weights": {"len": -0.5009000000000001, "depth": 0.25045000000000006, "success": 5.945000000000001}}
{"cycle": 49, "candidates_processed": 6, "proofs_verified": 4, "abstentions": 2, "abstention_rate": 0.3333333333333333, "policy_weights": {"len": -0.5010000000000001, "depth": 0.25050000000000006, "success": 5.950000000000001}}
