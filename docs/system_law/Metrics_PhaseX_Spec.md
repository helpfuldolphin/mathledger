# Metrics Phase X Specification

**Version:** 1.2.0
**Status:** Design Freeze
**Phase:** X (P3-P4 Coverage, P5 Planning Notes)
**Author:** CLAUDE D — Metrics Conformance Layer
**Date:** 2025-12-13

---

## 1. Overview

This specification defines the Metrics Layer as a formal Phase X input vector with complete schemas and governance signal mapping. The Metrics Layer synthesizes three core sub-signals (Drift Compass, Budget View, FO Vital Signs) into a unified governance decision that feeds into the Phase X governance gate.

### 1.1 Design Principles

1. **SHADOW MODE**: All P3/P4 operations are observation-only. No control paths.
2. **Schema-First**: All signals conform to JSON Schema draft-07 specifications.
3. **Deterministic**: Given identical inputs, outputs are reproducible.
4. **Traceable**: All signals include cryptographic audit trails.
5. **Layered**: Metrics Layer integrates with existing governance layers (replay, topology, security, HT).

### 1.2 Scope

| Phase | Mode | Capabilities |
|-------|------|--------------|
| P3 (Synthetic) | SHADOW | Synthetic state observation, red-flag logging, drift detection |
| P4 (Shadow Coupling) | SHADOW | Real runner observation, twin comparison, divergence classification |
| P5 (Active) | ACTIVE | Governance enforcement (NOT AUTHORIZED) |

---

## 2. Architecture

### 2.1 Signal Flow

```
┌─────────────────────────────────────────────────────────────────────────┐
│                          METRICS LAYER                                   │
│                                                                          │
│  ┌─────────────────┐  ┌──────────────────┐  ┌──────────────────────┐   │
│  │  Drift Compass  │  │   Budget View    │  │   FO Vital Signs     │   │
│  │                 │  │                  │  │                      │   │
│  │  - drift_mag    │  │  - utilization   │  │  - success_rate      │   │
│  │  - axes[]       │  │  - allocations[] │  │  - health_status     │   │
│  │  - poly_cause   │  │  - constraints[] │  │  - trends            │   │
│  └────────┬────────┘  └────────┬─────────┘  └──────────┬───────────┘   │
│           │                    │                        │               │
│           └────────────────────┼────────────────────────┘               │
│                                ▼                                        │
│                    ┌───────────────────────┐                            │
│                    │  Governance Signal    │                            │
│                    │  Synthesizer          │                            │
│                    │                       │                            │
│                    │  - conflict_matrix    │                            │
│                    │  - alignment_state    │                            │
│                    │  - final_verdict      │                            │
│                    └───────────┬───────────┘                            │
│                                │                                        │
└────────────────────────────────┼────────────────────────────────────────┘
                                 ▼
                    ┌───────────────────────┐
                    │  Phase X Governance   │
                    │  Gate                 │
                    │                       │
                    │  - safe_for_promotion │
                    │  - recommended_action │
                    └───────────────────────┘
```

### 2.2 Layer Integration

The Metrics Layer occupies the `LAYER_METRICS` position in the governance verifier hierarchy:

```python
LAYER_METRICS = "metrics"
LAYER_BUDGET = "budget"

# Upstream dependencies
upstream = [LAYER_REPLAY, LAYER_TOPOLOGY]

# Downstream consumers
downstream = [LAYER_GOVERNANCE, LAYER_ADMISSIBILITY]
```

---

## 3. Required Metrics — P3 (Synthetic)

Phase III operates on synthetic state generated by the FirstLightShadowRunner. All metrics are observation-only.

### 3.1 Core Metrics

| Metric | Source | Type | Range | Description |
|--------|--------|------|-------|-------------|
| `success_rate` | FOVitalSigns | float | 0-100% | Rolling window success rate |
| `abstention_rate` | FOVitalSigns | float | 0-100% | Rolling window abstention rate |
| `duration_seconds` | FOVitalSigns | float | 0+ | Last run duration |
| `health_status` | FOVitalSigns | enum | ALIVE/DEGRADED/CRITICAL/UNKNOWN | Computed health indicator |
| `runs_total` | FOVitalSigns | int | 0+ | Total run counter |

### 3.2 Trend Metrics

| Metric | Type | Values | Description |
|--------|------|--------|-------------|
| `duration_trend` | enum | up/down/flat | Duration change direction |
| `abstention_trend` | enum | up/down/flat | Abstention change direction |
| `success_trend` | enum | up/down/flat | Success rate change direction |

### 3.3 Drift Compass Metrics (P3)

| Metric | Type | Threshold | Critical | Description |
|--------|------|-----------|----------|-------------|
| `success_rate_drift` | float | 0.10 | 0.20 | Deviation from baseline success |
| `abstention_drift` | float | 0.15 | 0.25 | Deviation from baseline abstention |
| `duration_drift` | float | 0.20 | 0.40 | Deviation from baseline duration |
| `rsi_drift` | float | 0.15 | 0.30 | RSI deviation (if available) |

### 3.4 Budget Metrics (P3)

| Resource | Default Allocation | Warning % | Critical % |
|----------|-------------------|-----------|------------|
| `derivation_steps` | 1000/run | 80% | 95% |
| `verification_calls` | 500/run | 80% | 95% |
| `memory_mb` | 512 | 85% | 95% |
| `time_ms` | 60000 | 75% | 90% |

### 3.5 P3 Red-Flag Conditions

Red-flags are logged but never enforced:

| Flag Code | Condition | Severity |
|-----------|-----------|----------|
| CDI-010 | Abstention threshold exceeded | WARN |
| CDI-007 | Consecutive failure streak ≥3 | WARN |
| RSI-COLLAPSE | ρ < 0.2 for ≥5 cycles | CRITICAL |
| OMEGA-EXIT | Unexpected omega region exit | WARN |
| BLOCK-RATE-EXPLOSION | β > 0.6 | CRITICAL |
| HARD-FAIL | HARD mode verification failure | CRITICAL |

### 3.6 P3 Output Artifacts

```
results/first_light/{run_id}/
├── cycles.jsonl              # first_light_synthetic_raw.schema.json
├── red_flags.jsonl           # first_light_red_flag_matrix.schema.json
├── metrics.jsonl             # first_light_metrics_windows.schema.json
├── drift_compass.jsonl       # metric_drift_compass.schema.json
├── budget_view.jsonl         # metric_budget_joint_view.schema.json
├── governance_signal.jsonl   # metric_governance_signal.schema.json
└── summary.json              # first_light_stability_report.schema.json
```

---

## 4. Required Metrics — P4 (Shadow Coupling)

Phase IV couples to the real runner via read-only telemetry adapters. All operations remain SHADOW mode.

### 4.1 Real Runner Observation Metrics

| Metric | Source | Type | Description |
|--------|--------|------|-------------|
| `real_delta_p` | USLAIntegrationAdapter | float | Observed delta-p from real runner |
| `real_H` | USLAIntegrationAdapter | float | Real runner H value |
| `real_rho` | USLAIntegrationAdapter | float | Real runner RSI (ρ) |
| `real_tau` | USLAIntegrationAdapter | float | Real runner threshold (τ) |
| `real_beta` | USLAIntegrationAdapter | float | Real runner block rate (β) |
| `real_in_omega` | USLAIntegrationAdapter | bool | Real runner omega state |
| `real_success` | USLAIntegrationAdapter | bool | Real runner success state |

### 4.2 Twin Prediction Metrics

| Metric | Type | Description |
|--------|------|-------------|
| `twin_delta_p` | float | Shadow twin predicted delta-p |
| `twin_H` | float | Shadow twin H prediction |
| `twin_rho` | float | Shadow twin RSI prediction |
| `twin_tau` | float | Shadow twin threshold prediction |
| `twin_beta` | float | Shadow twin block rate prediction |
| `twin_in_omega` | bool | Shadow twin omega prediction |
| `twin_success` | bool | Shadow twin success prediction |

### 4.3 Divergence Classifier Metrics

| Metric | Type | Threshold | Description |
|--------|------|-----------|-------------|
| `divergence` | float | - | \|real_delta_p - twin_delta_p\| |
| `divergence_pct` | float | - | Percentage divergence |
| `H_diff` | float | ε=0.1 | H value divergence |
| `rho_diff` | float | ε=0.15 | RSI divergence |
| `tau_diff` | float | ε=0.05 | Threshold divergence |
| `beta_diff` | float | ε=0.1 | Block rate divergence |
| `omega_mismatch` | bool | - | Omega state disagreement |
| `success_mismatch` | bool | - | Success state disagreement |

### 4.4 Divergence Severity Classification

| Severity | Conditions |
|----------|------------|
| NONE | All metrics within ε thresholds |
| MINOR | Single metric exceeds ε, others OK |
| MODERATE | 2-3 metrics exceed ε OR streak ≥3 cycles |
| SEVERE | ≥4 metrics exceed ε OR streak ≥10 cycles |

### 4.5 P4 Alert Thresholds

Per Phase_X_Divergence_Metric.md:

| Metric | ε | Warning Cycles | Critical Cycles |
|--------|---|----------------|-----------------|
| Governance decision | exact | 3 | 10 |
| HSS (H) | 0.1 | 3 | 10 |
| Threshold τ | 0.05 | 3 | 10 |
| RSI ρ | 0.15 | INFO only | INFO only |
| Block rate β | 0.1 | INFO only | INFO only |

### 4.6 P4 Output Artifacts

```
results/first_light_p4/{run_id}/
├── real_cycles.jsonl         # Real runner observations
├── twin_cycles.jsonl         # Shadow twin predictions
├── divergence.jsonl          # p4_divergence_log.schema.json
├── drift_compass.jsonl       # metric_drift_compass.schema.json
├── budget_view.jsonl         # metric_budget_joint_view.schema.json
├── governance_signal.jsonl   # metric_governance_signal.schema.json
├── red_flags.jsonl           # Anomaly observations
├── metrics.jsonl             # Windowed metrics
└── summary.json              # Run summary
```

---

## 5. Divergence-Classifier Implications

### 5.1 Integration with Governance Signal

The divergence classifier feeds into the Metric Governance Signal as a fourth sub-signal during P4:

```json
{
  "sub_signals": {
    "drift_compass": { ... },
    "budget_view": { ... },
    "fo_vital_signs": { ... },
    "divergence_classifier": {
      "status": "OK|WARN|BLOCK",
      "severity": "NONE|MINOR|MODERATE|SEVERE",
      "streak_length": 0,
      "twin_correlation": true
    }
  }
}
```

### 5.2 Divergence-to-Governance Mapping

| Divergence Severity | Governance Status | Action |
|---------------------|-------------------|--------|
| NONE | OK | CONTINUE |
| MINOR | OK | MONITOR |
| MODERATE | WARN | INVESTIGATE |
| SEVERE | BLOCK | HALT |

### 5.3 Conflict Resolution

When divergence classifier conflicts with other sub-signals:

1. **Divergence SEVERE + FO ALIVE**: Log conflict, use BLOCK (conservative)
2. **Divergence NONE + FO CRITICAL**: Use FO signal (FO authoritative for health)
3. **Divergence MODERATE + Budget OK**: Use WARN (divergence takes precedence over budget)

### 5.4 Twin Correlation Semantics

- `twin_correlation: true` — Divergence was predicted by twin model
- `twin_correlation: false` — Unexpected divergence (higher concern)

Uncorrelated divergence escalates severity by one level.

### 5.5 Recommended First Divergence Axis

**Advisory Note:** When beginning P4 divergence analysis, start with `mean_tau_error` as the primary observation axis. This is a recommended starting point, not required.

**Rationale:**
- τ (threshold) is the most directly actionable parameter in the governance model
- τ divergence between twin and real runner indicates calibration drift
- τ changes propagate predictably to downstream metrics (ρ, β)
- ρ (RSI) can fluctuate due to workload variance without indicating model error

**Reading p50/p95 Changes:**

| Percentile | Interpretation |
|------------|----------------|
| p50 (median) | Typical divergence magnitude; use for baseline drift detection |
| p95 | Tail divergence; use to identify outlier cycles requiring investigation |

**Advisory Guidance:**
- If p50 shifts upward across windows → systematic calibration drift (investigate model)
- If p95 spikes but p50 stable → transient anomalies (continue observation)
- If both p50 and p95 shift → potential model-real coupling gap (escalate to P5 planning)

This axis selection is advisory only and does not establish thresholds or enforcement. This does not set pass/fail criteria; see CAL_EXP_2_* documents for experimental criteria.

---

## 6. Phase V Transition Notes (P5)

**Status:** NOT AUTHORIZED — Planning Reference Only

This section documents anticipated metric behavior changes when transitioning from synthetic/shadow telemetry to real production telemetry. These notes inform future P5 planning but do **not** authorize any P5 implementation.

### 6.1 Real Telemetry Variance Expectations

Real telemetry will differ from P3 mock data in predictable ways:

| Metric | P3 Synthetic | P5 Real (Expected) | Reason |
|--------|--------------|-------------------|--------|
| `success_rate` | Stable (85-98%) | Higher variance (70-99%) | Real proof complexity varies |
| `block_rate` (β) | Narrow band (0.02-0.08) | Wider band (0.01-0.15) | Real derivation paths unpredictable |
| `duration_seconds` | Uniform (~2-5s) | Long-tail distribution (1-30s) | Complex proofs take longer |
| `abstention_rate` | Low, stable (~2%) | Bursty (0-12%) | Depends on input queue |

### 6.2 Block Threshold Adjustments

P5 may require adjusted thresholds to avoid false positives:

| Threshold | P3/P4 Value | P5 Recommended | Rationale |
|-----------|-------------|----------------|-----------|
| `_DRIFT_WARN_THRESHOLD` | 0.30 | 0.35 | Real metrics more volatile |
| `_DRIFT_CRITICAL_THRESHOLD` | 0.70 | 0.75 | Avoid false BLOCK on variance |
| `_SUCCESS_RATE_WARN_THRESHOLD` | 80% | 75% | Real workloads harder |
| `_SUCCESS_RATE_CRITICAL_THRESHOLD` | 50% | 45% | Accommodate proof complexity |
| `_BUDGET_WARN_THRESHOLD` | 80% | 85% | Real utilization less uniform |

These adjustments are **provisional** and require P5 calibration runs before adoption.

### 6.3 Safe Comparison Band (P3 Mock vs P5 Real)

When comparing P3 synthetic metrics to P5 real metrics, use the following safe comparison bands. Metrics within these bands are considered **compatible**; deviations outside indicate model drift requiring investigation.

| Metric | Safe Band | Formula | Notes |
|--------|-----------|---------|-------|
| `success_rate` | ±15% | `|P3 - P5| ≤ 15` | Core health indicator |
| `block_rate` | ±0.08 | `|β_P3 - β_P5| ≤ 0.08` | Block behavior check |
| `abstention_rate` | ±5% | `|abs_P3 - abs_P5| ≤ 5` | Abstention baseline |
| `drift_magnitude` | ±0.15 | `|drift_P3 - drift_P5| ≤ 0.15` | Drift compass calibration |
| `budget_utilization` | ±10% | `|util_P3 - util_P5| ≤ 10` | Resource tracking |

**Interpretation:**

- **Within band**: P3 model remains valid predictor; proceed with confidence.
- **Outside band (single metric)**: Log divergence, monitor for 3 cycles.
- **Outside band (≥2 metrics)**: Model recalibration required before P5 gate.

### 6.4 P5 Invariant Additions

When P5 is authorized, add these invariants to Section 8:

| ID | Invariant | Description |
|----|-----------|-------------|
| INV-P5-01 | Real telemetry source verified | Adapter reads from production Redis |
| INV-P5-02 | Comparison band logged | Each cycle logs P3/P5 band position |
| INV-P5-03 | Threshold calibration dated | All threshold changes timestamped |

---

## 7. Schema Inventory

### 7.1 New Schemas (This Spec)

| Schema | Location | Purpose |
|--------|----------|---------|
| `metric_drift_compass.schema.json` | `schemas/metrics/` | Multi-axis drift tracking |
| `metric_budget_joint_view.schema.json` | `schemas/metrics/` | Joint budget allocation view |
| `metric_governance_signal.schema.json` | `schemas/metrics/` | Unified governance decision |

### 7.2 Related Schemas

| Schema | Location | Integration |
|--------|----------|-------------|
| `first_light_metrics_windows.schema.json` | `schemas/first_light/` | P3 windowed metrics |
| `first_light_red_flag_matrix.schema.json` | `schemas/first_light/` | P3 red-flag tracking |
| `p4_divergence_log.schema.json` | `schemas/phase_x_p4/` | P4 divergence records |
| `p4_twin_trajectory.schema.json` | `schemas/phase_x_p4/` | P4 twin predictions |
| `replay_safety_governance_signal.schema.json` | `schemas/replay_safety/` | Replay layer signal |

---

## 8. Governance Signal Mapping

### 8.1 Layer-to-Signal Adapter

```python
def adapt_metrics_to_governance_signal(
    drift_compass: Dict,
    budget_view: Dict,
    fo_vital_signs: Dict,
    divergence_classifier: Optional[Dict] = None,  # P4 only
) -> GovernanceSignal:
    """
    Synthesize metrics layer outputs into a GovernanceSignal
    for cross-layer governance integration.
    """
    return GovernanceSignal(
        layer=LAYER_METRICS,
        status=compute_final_status(...),
        severity=compute_severity(...),
        message=synthesize_message(...),
        reasons=collect_reasons(...),
        metadata={
            "drift_magnitude": drift_compass["drift_magnitude"],
            "budget_utilization": budget_view["utilization_pct"],
            "fo_health": fo_vital_signs["health_status"],
        }
    )
```

### 8.2 Cross-Layer Integration

| Source Layer | Target Layer | Signal Type |
|--------------|--------------|-------------|
| metrics | governance | GovernanceSignal |
| metrics | admissibility | safe_for_promotion |
| metrics | budget | throttle/boost signals |
| fo_vital_signs | rfl_runner | FOFeedbackSignal |

### 8.3 Governance Director Panel Integration

The Metric Governance Signal feeds into the Governance Director Panel:

```python
# Phase III: Director Console Feed
map_governance_to_director_status(verdict)  # -> GREEN/YELLOW/RED

# Phase IV: Chronicle Compass
build_governance_alignment_view(signals)    # -> alignment_score

# Phase V: Global Synthesizer
build_global_governance_director_panel(signals)  # -> full panel
```

---

## 9. Invariants

### 9.1 Mode Invariants (Non-Negotiable)

| ID | Invariant | Enforcement |
|----|-----------|-------------|
| INV-M01 | P3/P4 mode = SHADOW | Schema enum constraint |
| INV-M02 | No write to USLAIntegration | Adapter contract |
| INV-M03 | No governance modification | Read-only signals |
| INV-M04 | No abort enforcement | Log-only red flags |
| INV-M05 | All outputs tagged with mode | Schema required field |

### 9.2 Schema Invariants

| ID | Invariant | Enforcement |
|----|-----------|-------------|
| INV-S01 | schema_version = "1.0.0" | Schema const |
| INV-S02 | timestamp in ISO 8601 | Schema format |
| INV-S03 | Hash fields are hex | Schema pattern |
| INV-S04 | All required fields present | Schema required |

### 9.3 Operational Invariants

| ID | Invariant | Description |
|----|-----------|-------------|
| INV-O01 | Deterministic synthesis | Same inputs → same output |
| INV-O02 | Audit trail complete | All signals have hashes |
| INV-O03 | No side effects | Pure functions only |

---

## 10. Export Reconciliation

### 10.1 Current `backend/metrics/__init__.py` Exports

```python
__all__ = [
    "FirstOrganismRunResult",
    "FirstOrganismTelemetry",
    "emit_first_organism_metrics",
    "get_telemetry",
]
```

### 10.2 Recommended Additional Exports

To support Phase X governance binding, the following should be exported:

```python
# From fo_schema.py
from backend.metrics.fo_schema import (
    FOVitalSigns,
    FOTrendSeries,
    FOFeedbackSignal,
    REDIS_KEY_PREFIX,
    STATUS_SUCCESS,
    STATUS_FAILURE,
    TREND_UP,
    TREND_DOWN,
    TREND_FLAT,
    HISTORY_MAX_LEN,
    generate_sparkline,
    generate_trend_indicator,
)

# From fo_feedback.py
from backend.metrics.fo_feedback import (
    FOFeedbackReader,
    FOFeedbackWriter,
    get_fo_feedback_signal,
    record_fo_feedback_decision,
)
```

### 10.3 Reconciliation Patch

See `backend/metrics/__init__.py.patch` for the recommended export reconciliation.

---

## 11. Implementation Checklist

### 11.1 P3 Implementation

- [ ] Wire DriftCompassBuilder to FirstLightShadowRunner
- [ ] Wire BudgetViewBuilder to FirstLightShadowRunner
- [ ] Wire GovernanceSignalSynthesizer to FirstLightShadowRunner
- [ ] Emit drift_compass.jsonl per run
- [ ] Emit budget_view.jsonl per run
- [ ] Emit governance_signal.jsonl per run
- [ ] Validate all outputs against schemas

### 11.2 P4 Implementation

- [ ] Wire DivergenceClassifier to GovernanceSignalSynthesizer
- [ ] Add divergence_classifier sub-signal to governance signal
- [ ] Implement twin_correlation tracking
- [ ] Emit P4-specific artifacts
- [ ] Validate all outputs against schemas

### 11.3 Schema Validation

- [ ] Integrate JSON Schema validation in test suite
- [ ] Add schema version checks to loaders
- [ ] Validate example conformance in CI

---

## Appendix A: Schema URIs

| Schema | URI |
|--------|-----|
| metric_drift_compass | `https://mathledger.org/schemas/metrics/drift_compass.v1.0.0.json` |
| metric_budget_joint_view | `https://mathledger.org/schemas/metrics/budget_joint_view.v1.0.0.json` |
| metric_governance_signal | `https://mathledger.org/schemas/metrics/governance_signal.v1.0.0.json` |

---

## Appendix B: Glossary

| Term | Definition |
|------|------------|
| FO | First Organism — operational health telemetry system |
| RSI (ρ) | Rate of Successful Iteration — success metric |
| HSS (H) | Health State Score |
| Drift Compass | Multi-axis metric deviation tracking |
| Poly-cause | Multiple axes drifting simultaneously |
| Twin | Shadow model predicting real runner behavior |
| SHADOW mode | Observation-only, no enforcement |

---

## Appendix C: References

- `docs/system_law/Phase_X_P3_Spec.md` — P3 First Light specification
- `docs/system_law/Phase_X_P4_Spec.md` — P4 Shadow Coupling specification
- `backend/metrics/fo_schema.py` — FOVitalSigns canonical schema
- `backend/metrics/fo_feedback.py` — FO Feedback Loop integration
- `backend/analytics/governance_verifier.py` — Governance layer constants

---

## Appendix D: Metrics Dual Eval Golden Bundle Snippet

**Version:** 1.2.0
**Module:** `backend/health/metrics_dual_eval_annex.py`
**Purpose:** External verification reference for `signals.metrics_dual_eval`

### D.1 Golden Signal Shape

```json
{
  "schema_version": "1.2.0",
  "mode": "SHADOW",
  "diverges": true,
  "bands_differ_count": 2,
  "differing_metrics": ["budget_pct", "drift_magnitude"],
  "mock_status": "GREEN",
  "real_status": "YELLOW",
  "extraction_source": "MANIFEST",
  "source_provenance": {
    "path": "results/p3/metrics_windows.json",
    "sha256": "a1b2c3d4e5f6..."
  },
  "artifact_ref": {
    "artifact_type": "metrics_dual_eval_annex",
    "path": "results/p3/dual_eval_annex.json",
    "sha256": "f6e5d4c3b2a1...",
    "schema_version": "1.2.0"
  }
}
```

### D.2 Field Rules

| Field | Type | Required | Condition |
|-------|------|----------|-----------|
| `schema_version` | string | YES | Always `"1.2.0"` |
| `mode` | string | YES | Always `"SHADOW"` (P3/P4 only) |
| `diverges` | bool | YES | `true` if MOCK ≠ REAL status |
| `bands_differ_count` | int | YES | Count of metrics outside safe band |
| `differing_metrics` | string[] | YES | Sorted list of divergent metric names |
| `mock_status` | string | YES | `"GREEN"` \| `"YELLOW"` \| `"RED"` |
| `real_status` | string | YES | `"GREEN"` \| `"YELLOW"` \| `"RED"` |
| `extraction_source` | string | YES | `"MANIFEST"` \| `"EVIDENCE_JSON"` \| `"MISSING"` |
| `source_provenance` | object | CONDITIONAL | Present only when `source_sha256` provided |
| `artifact_ref` | object | CONDITIONAL | Present only when `annex_artifact_sha256` provided |

### D.3 Extraction Source Rules

| Source | Condition | Meaning |
|--------|-----------|---------|
| `MANIFEST` | `source_sha256` provided | Artifact located via manifest with verified hash |
| `EVIDENCE_JSON` | Explicit override | Artifact extracted from evidence.json payload |
| `MISSING` | No sha256 available | Artifact not cryptographically verified |

### D.4 Artifact Reference Rules

The `artifact_ref` block is **only present** when `annex_artifact_sha256` is provided:

```python
# With sha256 → artifact_ref present
attach_dual_eval_to_evidence(
    evidence,
    metrics,
    annex_artifact_sha256="f6e5d4c3b2a1..."
)
# Result: {"artifact_ref": {...}, ...}

# Without sha256 → no artifact_ref
attach_dual_eval_to_evidence(evidence, metrics)
# Result: no "artifact_ref" key
```

### D.5 GGFL Alignment View Shape

For Global Governance First Light (GGFL) integration:

```json
{
  "signal_type": "SIG-MET",
  "status": "warn",
  "conflict": false,
  "drivers": [
    "bands_differ_count=2",
    "budget_pct",
    "drift_magnitude"
  ],
  "driver_codes": [
    "DRIVER_BANDS_DIFFER_PRESENT",
    "DRIVER_TOP_METRICS_PRESENT"
  ],
  "summary": "Metrics dual-eval divergence: 2 band(s) differ (MOCK=GREEN, REAL=YELLOW)",
  "extraction_source": "MANIFEST",
  "artifact_ref": {
    "artifact_type": "metrics_dual_eval_annex",
    "path": "results/p3/metrics_windows.json",
    "sha256": "a1b2c3d4e5f6...",
    "schema_version": "1.2.0"
  }
}
```

### D.6 Driver Reason Codes

| Code | Meaning |
|------|---------|
| `DRIVER_BANDS_DIFFER_PRESENT` | `bands_differ_count > 0` |
| `DRIVER_TOP_METRICS_PRESENT` | `differing_metrics` is non-empty |

### D.7 Warning Line Format (Cap = 1)

Single-line warning format for status panels:

```
Metrics dual-eval: 2 band(s) differ (MOCK=GREEN, REAL=YELLOW); top3: [budget_pct, drift_magnitude]
```

**Format template:**
```
Metrics dual-eval: {bands_differ_count} band(s) differ (MOCK={mock_status}, REAL={real_status}); top3: [{sorted_top3_metrics}]
```

### D.8 Verification Checklist

| Check | Expected |
|-------|----------|
| `schema_version` | `"1.2.0"` |
| `mode` | `"SHADOW"` |
| `differing_metrics` sorted | Alphabetical order |
| `drivers` max length | 3 |
| `driver_codes` deterministic | Same input → same codes |
| `artifact_ref` present | Only when sha256 provided |
| Warning line count | Exactly 1 |

### D.9 Python Import Reference

```python
from backend.health.metrics_dual_eval_annex import (
    DUAL_EVAL_ANNEX_SCHEMA_VERSION,
    DRIVER_BANDS_DIFFER_PRESENT,
    DRIVER_TOP_METRICS_PRESENT,
    EXTRACTION_SOURCE_MANIFEST,
    EXTRACTION_SOURCE_EVIDENCE_JSON,
    EXTRACTION_SOURCE_MISSING,
    build_metrics_dual_eval_annex,
    attach_dual_eval_to_evidence,
    build_dual_eval_status_summary,
    metrics_dual_eval_for_alignment_view,
    format_dual_eval_warning_line,
)
```

### D.10 Cross-References

| Resource | Path |
|----------|------|
| **Primary Adapter Module** | `backend/health/metrics_dual_eval_annex.py` |
| **Primary Test File** | `tests/ci/test_metrics_dual_eval_annex.py` |

**Pytest Command:**
```bash
uv run python -m pytest tests/ci/test_metrics_dual_eval_annex.py -v --tb=short
```

### D.11 Compliance Notes

1. **Warning Cap**: All warnings MUST be single-line (cap=1).
2. **Driver Format**: Drivers use reason codes only (`DRIVER_BANDS_DIFFER_PRESENT`, `DRIVER_TOP_METRICS_PRESENT`), not prose.
3. **Determinism**: Given identical inputs, all outputs (including `differing_metrics`, `drivers`, `driver_codes`) MUST be reproducible.

---

*End of Specification*
