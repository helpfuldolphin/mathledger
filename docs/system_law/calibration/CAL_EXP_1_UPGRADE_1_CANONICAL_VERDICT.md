# CAL-EXP-1 UPGRADE-1: Canonical Verdict

**Date**: 2025-12-12
**Status**: RECONCILED
**Schema Version**: 1.0.0

---

## Provenance Block

### Git State
```
Commit SHA: fd6fd079c43385651aa4ddd47861fdc1c8c70d27
Branch: master
```

### BASELINE Runs

**Seed=42**
```
Command: python scripts/run_p5_cal_exp1.py --seed 42 --cycles 200 --window-size 50 --verify-replay --output-dir results/p5_cal_exp1/synthetic_seed42
Adapter Mode: SYNTHETIC
Config Path: None (default)
LR Overrides: None (baseline lr=0.1 uniform)
Run ID: cal_exp1_20251212_091922
Artifacts:
  - results/p5_cal_exp1/synthetic_seed42/cal_exp1_20251212_091922/cal_exp1_report.json
  - results/p5_cal_exp1/synthetic_seed42/cal_exp1_20251212_091922/cal_exp1_metrics.json
  - results/p5_cal_exp1/synthetic_seed42/cal_exp1_20251212_091922/cal_exp1_summary.json
```

**Seed=43**
```
Command: python scripts/run_p5_cal_exp1.py --seed 43 --cycles 200 --window-size 50 --verify-replay --output-dir results/p5_cal_exp1/synthetic_seed43
Adapter Mode: SYNTHETIC
Config Path: None (default)
LR Overrides: None (baseline lr=0.1 uniform)
Run ID: cal_exp1_20251212_091945
Artifacts:
  - results/p5_cal_exp1/synthetic_seed43/cal_exp1_20251212_091945/cal_exp1_report.json
  - results/p5_cal_exp1/synthetic_seed43/cal_exp1_20251212_091945/cal_exp1_metrics.json
  - results/p5_cal_exp1/synthetic_seed43/cal_exp1_20251212_091945/cal_exp1_summary.json
```

### UPGRADE-1 Runs

**Seed=42**
```
Command: python scripts/run_p5_cal_exp1.py --seed 42 --cycles 200 --window-size 50 --verify-replay --lr-H 0.20 --lr-rho 0.15 --lr-tau 0.02 --lr-beta 0.12 --upgrade-label UPGRADE-1 --output-dir results/p5_cal_exp1/upgrade1_seed42
Adapter Mode: SYNTHETIC
LR Overrides: {"H": 0.20, "rho": 0.15, "tau": 0.02, "beta": 0.12}
Run ID: cal_exp1_20251212_095143
Artifacts:
  - results/p5_cal_exp1/upgrade1_seed42/cal_exp1_20251212_095143/cal_exp1_report.json
  - results/p5_cal_exp1/upgrade1_seed42/cal_exp1_20251212_095143/cal_exp1_metrics.json
  - results/p5_cal_exp1/upgrade1_seed42/cal_exp1_20251212_095143/cal_exp1_summary.json
```

**Seed=43**
```
Command: python scripts/run_p5_cal_exp1.py --seed 43 --cycles 200 --window-size 50 --verify-replay --lr-H 0.20 --lr-rho 0.15 --lr-tau 0.02 --lr-beta 0.12 --upgrade-label UPGRADE-1 --output-dir results/p5_cal_exp1/upgrade1_seed43
Adapter Mode: SYNTHETIC
LR Overrides: {"H": 0.20, "rho": 0.15, "tau": 0.02, "beta": 0.12}
Run ID: cal_exp1_20251212_095159
Artifacts:
  - results/p5_cal_exp1/upgrade1_seed43/cal_exp1_20251212_095159/cal_exp1_report.json
  - results/p5_cal_exp1/upgrade1_seed43/cal_exp1_20251212_095159/cal_exp1_metrics.json
  - results/p5_cal_exp1/upgrade1_seed43/cal_exp1_20251212_095159/cal_exp1_summary.json
```

---

## Canonical Metric Definitions

**Source**: `cal_exp1_report.json` (generated by `scripts/run_p5_cal_exp1.py`)

| Metric | Field Path | Definition |
|--------|------------|------------|
| `divergence_rate` | `windows[i].divergence_rate` | Fraction of cycles where `is_diverged()=True`. Predicate: `abs(delta_p) > 0.05`. Type: "any divergence" (not decomposed). |
| `mean_delta_p` | `windows[i].mean_delta_p` | Mean of `abs(delta_p)` over window cycles. This is a MAGNITUDE, not signed. |
| `delta_bias` | `windows[i].delta_bias` | `mean_delta_p * (0.5 - divergence_rate)`. WARNING: This is a HEURISTIC, not true signed bias. |
| `phase_lag_xcorr` | `windows[i].phase_lag_xcorr` | Lag-1 autocorrelation of delta_p series. |

### Critical Observation

The `delta_bias` field is **NOT** true bias (Twin - Real).

Formula: `delta_bias = mean_delta_p * (0.5 - divergence_rate)`

When `divergence_rate = 1.0`: `delta_bias = -0.5 * mean_delta_p`

This means `delta_bias` tracks `mean_delta_p` inversely when divergence is saturated. It does NOT indicate whether Twin overestimates or underestimates Real.

### Divergence Decomposition

**Status**: NOT AVAILABLE in `cal_exp1_report.json`

The harness computes only aggregate "any divergence" rate. Success/omega/blocked/state decomposition is not present in these artifacts.

---

## Reconciled Metrics (from canonical artifacts)

### Seed=42 Comparison

| Metric | BASELINE | UPGRADE-1 | Delta |
|--------|----------|-----------|-------|
| mean_of_mean_delta_p | 0.048982 | 0.050262 | **+0.001280** |
| mean_delta_bias | -0.023814 | -0.024668 | -0.000854 |
| mean_divergence_rate | 0.985000 | 0.990000 | +0.005000 |
| mean_phase_lag | 0.656623 | 0.678605 | +0.021982 |
| slope_mean_delta_p | 0.001534 | 0.000895 | -0.000639 |
| final_divergence_rate | 1.000000 | 1.000000 | 0.000000 |

**Assessment**: WORSENED (mean_delta_p increased by +0.0013)

### Seed=43 Comparison

| Metric | BASELINE | UPGRADE-1 | Delta |
|--------|----------|-----------|-------|
| mean_of_mean_delta_p | 0.056614 | 0.056323 | **-0.000291** |
| mean_delta_bias | -0.028082 | -0.027726 | +0.000356 |
| mean_divergence_rate | 0.995000 | 0.990000 | -0.005000 |
| mean_phase_lag | 0.780818 | 0.753791 | **-0.027027** |
| slope_mean_delta_p | 0.005600 | 0.006826 | +0.001226 |
| final_divergence_rate | 1.000000 | 1.000000 | 0.000000 |

**Assessment**: MARGINALLY IMPROVED (mean_delta_p decreased by -0.0003, phase_lag decreased by -0.027)

---

## Reconciliation of Conflicting Reports

### Question: Which report used a non-canonical metric or different artifact?

**Finding**: The earlier "Report A" (referenced by user as showing "mean delta_p improved materially ~0.0275 -> ~0.0230") cannot be reconciled with the canonical artifacts.

The canonical artifacts show:
- BASELINE mean_delta_p: 0.049 (seed=42), 0.057 (seed=43)
- UPGRADE-1 mean_delta_p: 0.050 (seed=42), 0.056 (seed=43)

Values like "0.0275" and "0.0230" do not appear in any canonical artifact. Either:
1. Report A used a different run with different parameters
2. Report A computed a derived metric not present in artifacts
3. Report A referenced a different experiment (not CAL-EXP-1)

**Conclusion**: The Helper Report (my earlier report) correctly extracted values from canonical artifacts. Report A's values are unverifiable and should be disregarded for this decision.

### Question: Are we mixing harness "divergence_rate" with calibration "mean_delta_p"?

**Yes, this is a conceptual confusion.**

- `divergence_rate` = binary threshold crossing rate (0.05 threshold)
- `mean_delta_p` = continuous magnitude metric

When mean_delta_p hovers around 0.045-0.065, the 0.05 threshold will be crossed ~50-100% of the time, causing divergence_rate to saturate near 1.0 regardless of small improvements in mean_delta_p.

**The divergence_rate metric is not informative when mean_delta_p is near the threshold.**

### Question: Different windowing between reports?

Both reports use 50-cycle windows (4 windows over 200 cycles). No windowing discrepancy.

---

## Why divergence_rate Stays at 1.0

The divergence predicate is: `is_diverged() := abs(delta_p) > 0.05`

Canonical data shows:
- Seed=42 mean_delta_p range: 0.0451 - 0.0560
- Seed=43 mean_delta_p range: 0.0436 - 0.0657

Since mean_delta_p oscillates around the 0.05 threshold (sometimes above, sometimes below), the divergence_rate will remain saturated near 1.0.

**This is a structural property of the threshold choice, not a failure of UPGRADE-1.**

Per doctrine: We do NOT adjust thresholds during calibration. The model must be improved, not the ruler.

---

## Canonical Verdict

### Assessment

**UPGRADE-1: MIXED RESULTS**

| Seed | mean_delta_p Change | Phase Lag Change | Assessment |
|------|---------------------|------------------|------------|
| 42 | +0.0013 (WORSE) | +0.022 (WORSE) | WORSENED |
| 43 | -0.0003 (BETTER) | -0.027 (BETTER) | MARGINAL IMPROVEMENT |

Net effect: Inconclusive. One seed improved slightly, one worsened slightly.

### Decision

**ADJUST** - Propose minimal LR sweep before CAL-EXP-2

UPGRADE-1 did not achieve consistent improvement. The per-component LRs may need further tuning.

### Recommended Next Step

Conduct a minimal 2x2 LR sweep on H and rho only (the most impactful components):

| Run | H | rho | tau | beta |
|-----|---|-----|-----|------|
| UPGRADE-1 (baseline) | 0.20 | 0.15 | 0.02 | 0.12 |
| SWEEP-A | 0.25 | 0.15 | 0.02 | 0.12 |
| SWEEP-B | 0.20 | 0.20 | 0.02 | 0.12 |
| SWEEP-C | 0.25 | 0.20 | 0.02 | 0.12 |

Run each with seeds {42, 43}, verify replay, compare mean_delta_p.

If any sweep variant shows consistent improvement (both seeds), authorize that variant for extended testing. Otherwise, consider structural changes to the Twin model.

---

## Artifacts Preserved

| Path | Status |
|------|--------|
| results/p5_cal_exp1/synthetic_seed42/ | FROZEN |
| results/p5_cal_exp1/synthetic_seed43/ | FROZEN |
| results/p5_cal_exp1/upgrade1_seed42/ | FROZEN |
| results/p5_cal_exp1/upgrade1_seed43/ | FROZEN |
| docs/system_law/calibration/CAL_EXP_1.md | FROZEN |
| docs/system_law/calibration/CAL_EXP_1_UPGRADE_1_HELPER_REPORT.md | PRESERVED (UNRECONCILED) |
| docs/system_law/calibration/CAL_EXP_1_UPGRADE_1_CANONICAL_VERDICT.md | THIS DOCUMENT |
| scripts/reconcile_cal_exp1_metrics.py | RECONCILIATION SCRIPT |

---

**END OF CANONICAL VERDICT**
