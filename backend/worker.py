"""
MathLedger Worker (First Organism)

Handles the derivation and verification of mathematical statements using Lean 4.
Orchestrates the "Reasoning" side of the Dual Root Attestation system.

See MathLedger whitepaper §4.2 (Dual Root Attestation) and §3.1 (Verification Ladder).
"""
from __future__ import annotations

import json
import logging
import os
import pathlib
import subprocess
import time
import uuid
from dataclasses import dataclass
from typing import Callable, Optional

import psycopg
import redis

from backend.crypto.auth import get_redis_url_with_auth
from backend.crypto.core import hash_statement, sha256_hex
from backend.lean_interface import LeanStatement, sanitize_statement
from backend.lean_mode import (
    LeanMode,
    get_lean_mode,
    get_build_runner,
    get_lean_status,
    is_mock_abstention,
    ABSTENTION_SIGNATURE,
    MOCK_STDERR_FULL_HASH,
)
from normalization.taut import truth_table_is_tautology
from backend.repro.determinism import deterministic_uuid
from ledger.ingest import LedgerIngestor

# ---------------- Logger ----------------
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S"
)
logger = logging.getLogger("LedgerWorker")

# ---------------- Config ----------------
from backend.security.runtime_env import MissingEnvironmentVariable, get_database_url

REDIS_URL = get_redis_url_with_auth()
try:
    DATABASE_URL = get_database_url()
except MissingEnvironmentVariable as exc:
    raise RuntimeError(str(exc)) from exc
LEAN_PROJECT_DIR = os.environ.get(
    "LEAN_PROJECT_DIR",
    r"C:\dev\mathledger\backend\lean_proj",
)
QUEUE_KEY = os.environ.get("QUEUE_KEY", "ml:jobs")

MAX_JOBS = 500
LEAN_BUILD_TIMEOUT = int(os.environ.get("LEAN_BUILD_TIMEOUT", "90"))


# ---------------- Helpers ----------------
def remove_build_artifacts(job_id: str) -> None:
    build_dir = pathlib.Path(LEAN_PROJECT_DIR) / "build" / "lib" / "ML" / "Jobs"
    for suffix in (".olean", ".c"):
        target = build_dir / f"job_{job_id}{suffix}"
        try:
            target.unlink()
        except FileNotFoundError:
            continue
        except Exception:
            continue


def tidy_jobs_dir(jobs_dir: str) -> None:
    jobs_path = pathlib.Path(jobs_dir)
    files = sorted(
        jobs_path.glob("job_*.lean"),
        key=lambda p: p.stat().st_mtime,
        reverse=True,
    )
    for f in files[MAX_JOBS:]:
        job_id = f.stem.split("_", 1)[-1]
        try:
            f.unlink()
        except FileNotFoundError:
            pass
        except Exception:
            continue
        else:
            remove_build_artifacts(job_id)


def ensure_namespace_dirs() -> str:
    ml_dir = pathlib.Path(LEAN_PROJECT_DIR) / "ML"
    jobs_dir = ml_dir / "Jobs"
    jobs_dir.mkdir(parents=True, exist_ok=True)

    jobs_mod = ml_dir / "Jobs.lean"
    if not jobs_mod.exists():
        jobs_mod.write_text(
            "namespace ML.Jobs\nend ML.Jobs\n",
            encoding="utf-8",
            newline="\n",
        )

    return str(jobs_dir)


def lean_module_name(job_id: str) -> str:
    return f"ML.Jobs.job_{job_id}"


def lean_file_path(jobs_dir: str, job_id: str) -> str:
    return os.path.join(jobs_dir, f"job_{job_id}.lean")


def statement_from_payload(data: dict) -> Optional[LeanStatement]:
    raw = (
        data.get("canonical")
        or data.get("goal_type")
        or data.get("statement")
        or data.get("formula")
        or data.get("goal")
    )
    stmt = sanitize_statement(raw)
    if stmt.is_empty():
        return None
    return stmt


def proof_body_for(canonical: str) -> str:
    lookup = {
        "p->p": "  intro hp\n  exact hp",
        "p/\\q->p": "  intro h\n  exact h.left",
        "p/\\q->q": "  intro h\n  exact h.right",
        "p->q->p": "  intro hp\n  intro hq\n  exact hp",
        "p->p\\/q": "  intro hp\n  apply Or.inl\n  exact hp",
        "q->p\\/q": "  intro hq\n  apply Or.inr\n  exact hq",
        "p/\\q->p/\\q": "  intro h\n  exact h",
        "(p->q)->(p->q)": "  intro hpq\n  exact hpq",
    }
    return lookup.get(canonical, "  admit")


def make_lean_source(job_id: str, stmt: LeanStatement, body: str) -> str:
    return (
        "import Mathlib\n\n"
        "namespace ML.Jobs\n\n"
        f"/-- Auto-generated by MathLedger worker for job {job_id} -/\n"
        "set_option linter.unusedVariables false\n"
        f"theorem job_{job_id} (p q r s t : Prop) : {stmt.lean} := by\n"
        f"{body}\n\n"
        "end ML.Jobs\n"
    )


def run_lake_build(module_name: str) -> subprocess.CompletedProcess[str]:
    """
    Run Lean build using the configured mode.

    The build runner is determined by ML_LEAN_MODE environment variable:
    - "mock": Pure mock (no Lean), deterministic abstention signature
    - "dry_run": Lean available, validate on minimal statement first
    - "full": Real Lean verification (default)

    See backend.lean_mode for full documentation.
    """
    # Get mode-aware build runner
    runner = get_build_runner(
        project_dir=LEAN_PROJECT_DIR,
        timeout=LEAN_BUILD_TIMEOUT,
    )
    return runner(module_name)


@dataclass(frozen=True)
class TautologyRetryResult:
    """Result of a tautology retry attempt."""

    success: bool
    lean_source: str
    build_result: subprocess.CompletedProcess[str]
    duration_ms: int


def retry_with_tautology_strategy(
    job_id: str,
    stmt: LeanStatement,
    jobs_dir: str,
    build_runner: Callable[[str], subprocess.CompletedProcess[str]] = run_lake_build,
) -> TautologyRetryResult:
    """
    Retry a failed Lean build using the tautology (by_decide) strategy.

    This is part of the Verification Ladder: when a direct proof fails,
    we check if the statement is a tautology and use `classical; decide`
    as a fallback proof strategy.

    Args:
        job_id: The job identifier
        stmt: The sanitized statement
        jobs_dir: Directory for Lean job files
        build_runner: Build runner function (mode-aware)

    Returns:
        TautologyRetryResult with retry outcome
    """
    mod = lean_module_name(job_id)
    abs_path = lean_file_path(jobs_dir, job_id)
    src = make_lean_source(job_id, stmt, "  classical\n  decide")

    try:
        write_lean_file(abs_path, src)
    except Exception as file_err:
        logger.error(f"[ERROR] TautologyStrategy: Write failed for {job_id}. Reason: {file_err}")
        return TautologyRetryResult(
            success=False,
            lean_source=src,
            build_result=subprocess.CompletedProcess(
                args=["lake", "build", mod],
                returncode=1,
                stdout="",
                stderr=str(file_err),
            ),
            duration_ms=0,
        )

    start = time.perf_counter()
    result = build_runner(mod)
    duration_ms = int((time.perf_counter() - start) * 1000)

    return TautologyRetryResult(
        success=(result.returncode == 0),
        lean_source=src,
        build_result=result,
        duration_ms=duration_ms,
    )


def write_lean_file(path: str, content: str) -> None:
    target = pathlib.Path(path)
    tmp_path = target.with_suffix(target.suffix + ".tmp")
    target.parent.mkdir(parents=True, exist_ok=True)
    tmp_path.write_text(content, encoding="utf-8", newline="\n")
    tmp_path.replace(target)


@dataclass(frozen=True)
class LeanJobResult:
    """Canonical Lean job descriptor linking verification → ledger (Whitepaper Verif. Ladder)."""

    job_id: str
    statement: LeanStatement
    lean_source: str
    build_result: subprocess.CompletedProcess[str]
    stdout_hash: str
    stderr_hash: str
    module_name: str
    duration_ms: int


def _hash_output(text: Optional[str]) -> str:
    payload = (text or "").encode("utf-8")
    return sha256_hex(payload)


def build_lean_mode_metadata(
    lean_job: LeanJobResult,
    lean_status: "LeanModeStatus",
    is_mock: bool,
) -> dict:
    """
    Build Lean mode metadata for RFL consumption.

    This metadata flows through the ledger to run_with_attestation()
    for policy updates based on Lean verification outcomes.

    Args:
        lean_job: The Lean job result
        lean_status: Current Lean mode status
        is_mock: Whether this was a mock abstention

    Returns:
        Dictionary with Lean mode metadata
    """
    return {
        "lean_mode": lean_status.effective_mode.value,
        "lean_configured_mode": lean_status.configured_mode.value,
        "lean_available": lean_status.lean_available,
        "is_mock_abstention": is_mock,
        "stdout_hash": lean_job.stdout_hash,
        "stderr_hash": lean_job.stderr_hash,
        "duration_ms": lean_job.duration_ms,
        "job_id": lean_job.job_id,
        "module_name": lean_job.module_name,
    }


# Import for type hint
from backend.lean_mode import LeanModeStatus


def execute_lean_job(
    raw_statement: str,
    *,
    jobs_dir: Optional[str] = None,
    build_runner: Callable[[str], subprocess.CompletedProcess[str]] = run_lake_build,
    cleanup: bool = True,
) -> LeanJobResult:
    """Standardized entry on the verification ladder/budgets (abstain gates) described in the whitepaper."""

    stmt = sanitize_statement(raw_statement)
    if stmt.is_empty():
        raise ValueError("Statement is empty after sanitization")

    target_jobs_dir = jobs_dir or ensure_namespace_dirs()

    deterministic = deterministic_uuid(stmt.canonical)
    deterministic_uuid_obj = (
        deterministic if isinstance(deterministic, uuid.UUID) else uuid.UUID(str(deterministic))
    )
    jid = deterministic_uuid_obj.hex[:12]
    module_name = lean_module_name(jid)
    abs_path = lean_file_path(target_jobs_dir, jid)
    body = proof_body_for(stmt.canonical)
    src = make_lean_source(jid, stmt, body)

    try:
        write_lean_file(abs_path, src)
        start = time.perf_counter()
        result = build_runner(module_name)
        duration_ms = int((time.perf_counter() - start) * 1000)
        stdout_hash = _hash_output(result.stdout)
        stderr_hash = _hash_output(result.stderr)
        # Symbolic descent law: every Lean run must record its stdout/stderr digest.
        return LeanJobResult(
            job_id=jid,
            statement=stmt,
            lean_source=src,
            build_result=result,
            stdout_hash=stdout_hash,
            stderr_hash=stderr_hash,
            module_name=module_name,
            duration_ms=duration_ms,
        )
    finally:
        if cleanup:
            try:
                pathlib.Path(abs_path).unlink(missing_ok=True)
            except Exception:
                pass
            remove_build_artifacts(jid)
        # static comment: symbolic descent law demands we capture stderr/stdout hashes for every Lean run.


# ---------------- Main Loop ----------------
def main() -> None:
    jobs_dir = ensure_namespace_dirs()
    r = redis.from_url(REDIS_URL, decode_responses=True)

    # Log Lean mode status for First Organism transparency
    lean_status = get_lean_status()
    logger.info(f"[INIT] Lean mode: {lean_status.effective_mode.value} "
                f"(configured={lean_status.configured_mode.value}, "
                f"available={lean_status.lean_available})")
    if lean_status.will_abstain:
        logger.warning(f"[INIT] Running in mock mode - proofs will produce abstention signature")

    logger.info(f"[INIT] Connected to Redis. Listening on '{QUEUE_KEY}'.")

    tidy_jobs_dir(jobs_dir)
    ingestor = LedgerIngestor()

    with psycopg.connect(DATABASE_URL) as conn:
        while True:
            try:
                popped = r.blpop(QUEUE_KEY, timeout=5)
                if not popped:
                    continue
                _, payload = popped

                try:
                    data = json.loads(payload)
                except Exception:
                    logger.warning(f"[ABSTAIN] Worker: Skipping non-JSON payload. Payload={payload!r}")
                    continue

                theory = data.get("theory", "Propositional")
                stmt = statement_from_payload(data)
                if not stmt:
                    logger.warning(f"[ABSTAIN] Worker: No usable statement in job. Data={data}")
                    continue

                # Pre-compute job ID for axiom path (execute_lean_job will recompute for Lean path)
                try:
                    deterministic = deterministic_uuid(stmt.canonical)
                    deterministic_uuid_obj = (
                        deterministic
                        if isinstance(deterministic, uuid.UUID)
                        else uuid.UUID(str(deterministic))
                    )
                    jid = deterministic_uuid_obj.hex[:12]
                except Exception as ex:
                    # Fallback: use canonical hash of the statement content
                    # We use hash_statement to ensure domain separation (STMT)
                    full_hash = hash_statement(stmt.canonical)
                    jid = full_hash[:12]
                    logger.warning(f"[WARN] DeterministicUUID: Fallback trigger for {stmt.canonical}. Reason: {ex}")
                mod = lean_module_name(jid)

                with conn.cursor() as cur:
                    cur.execute(
                        """
                        SELECT is_axiom, derivation_rule, derivation_depth
                        FROM statements
                        WHERE content_norm = %s
                        """,
                        (stmt.canonical,),
                    )
                    stmt_info = cur.fetchone()
                is_axiom = bool(stmt_info[0]) if stmt_info else False
                derivation_rule = stmt_info[1] if stmt_info else None
                derivation_depth = stmt_info[2] if stmt_info else None

                ui_events_raw = data.get("ui_events")
                if not ui_events_raw:
                    ui_events_seq: tuple[str, ...] = ()
                elif isinstance(ui_events_raw, str):
                    ui_events_seq = (ui_events_raw,)
                else:
                    ui_events_seq = tuple(str(ev) for ev in ui_events_raw)

                truth_domain = data.get("truth_domain")

                if is_axiom:
                    logger.info(f"[AXIOM] Processing {jid} :: {stmt.ascii_pretty}")
                    with conn.cursor() as cur:
                        try:
                            outcome = ingestor.ingest(
                                cur,
                                theory_name=theory,
                                ascii_statement=stmt.ascii_pretty,
                                proof_text="",
                                prover="axiom",
                                status="success",
                                module_name=mod,
                                stdout="",
                                stderr="",
                                derivation_rule=derivation_rule,
                                derivation_depth=derivation_depth,
                                truth_domain=truth_domain,
                                is_axiom=True,
                                ui_events=ui_events_seq,
                                sealed_by="worker::axiom",
                                method="axiom",
                            )
                            conn.commit()
                            logger.info(
                                f"[AXIOM] Success {jid}. Block={outcome.block.number} Composite={outcome.block.composite_root}"
                            )
                        except Exception as db_e:
                            conn.rollback()
                            logger.error(f"[ERROR] LedgerIngestor: Database failure for {jid}. Reason: {db_e}")
                    continue

                lean_job = execute_lean_job(
                    stmt.ascii_pretty,
                    jobs_dir=jobs_dir,
                    build_runner=run_lake_build,
                    cleanup=False,
                )
                jid = lean_job.job_id  # Use job_id from execute_lean_job for consistency
                mod = lean_job.module_name
                src = lean_job.lean_source
                res = lean_job.build_result
                method_parts: list[str] = ["lake-build"]
                used_decide = False

                logger.info(f"[BUILD] Starting {mod} :: {stmt.ascii_pretty}")
                build_duration_ms = lean_job.duration_ms

                if res.returncode != 0:
                    logger.info(f"[FALLBACK] Build failed for {jid}. Checking tautology...")
                    if truth_table_is_tautology(stmt.canonical):
                        logger.info(f"[TAUT] Tautology detected for {jid}. Engaging by_decide strategy.")
                        retry_result = retry_with_tautology_strategy(
                            jid, stmt, jobs_dir, build_runner=run_lake_build
                        )
                        used_decide = True
                        method_parts.append("tautology-decide")
                        src = retry_result.lean_source
                        res = retry_result.build_result
                        build_duration_ms += retry_result.duration_ms
                        if retry_result.success:
                            logger.info(f"[TAUT] Proof SUCCESS for {jid}.")
                        else:
                            logger.info(f"[TAUT] Proof FAILED for {jid}.")
                            used_decide = False  # Mark as failed if retry didn't work
                    else:
                        logger.info(f"[FAIL] Not a tautology. Build permanently failed for {jid}.")

                status = "success" if res.returncode == 0 else "failure"

                # Detect mock abstention for First Organism transparency
                is_mock = is_mock_abstention(res.stderr or "")
                if is_mock:
                    prover = "mock_abstain"
                    method_parts.append("mock-abstain")
                    logger.info(f"[MOCK] Abstention detected for {jid} (ML_LEAN_MODE=mock)")
                elif used_decide:
                    prover = "by_decide" if status == "success" else "by_decide_failed"
                else:
                    prover = "lean4"
                method = "|".join(dict.fromkeys(method_parts))
                stdout = res.stdout or ""
                stderr = res.stderr or ""

                with conn.cursor() as cur:
                    try:
                        outcome = ingestor.ingest(
                            cur,
                            theory_name=theory,
                            ascii_statement=stmt.ascii_pretty,
                            proof_text=src,
                            prover=prover,
                            status=status,
                            module_name=mod,
                            stdout=stdout,
                            stderr=stderr,
                            derivation_rule=derivation_rule,
                            derivation_depth=derivation_depth,
                            truth_domain=truth_domain,
                            ui_events=ui_events_seq,
                            sealed_by="worker::proof",
                            method=method,
                            duration_ms=build_duration_ms,
                        )
                        conn.commit()
                        logger.info(
                            f"[PROOF] {status.upper()} {jid}. Block={outcome.block.number} Composite={outcome.block.composite_root}"
                        )
                    except Exception as db_e:
                        conn.rollback()
                        logger.error(f"[ERROR] LedgerIngestor: Database failure for {jid}. Reason: {db_e}")

                remove_build_artifacts(jid)

            except KeyboardInterrupt:
                logger.info("[SHUTDOWN] Worker stopping.")
                break
            except Exception as e:
                logger.error(f"[ERROR] WorkerLoop: Unhandled exception. Reason: {e}")
                time.sleep(1)


if __name__ == "__main__":
    main()


