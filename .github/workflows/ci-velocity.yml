name: CI Velocity (50% Target)

on:
  pull_request:
    branches: [ integrate/ledger-v0.1 ]
  push:
    branches: [ integrate/ledger-v0.1, mvdp-**, ci/devinA-velocity-v2-** ]

env:
  CI_VELOCITY_ENABLED: "true"
  CI_BASELINE_DURATION: "420"
  CI_TARGET_DURATION: "210"
  PYTHONUNBUFFERED: "1"

jobs:
  test:
    runs-on: ubuntu-latest
    services:
      postgres:
        image: postgres:15-alpine
        env:
          POSTGRES_USER: ml
          POSTGRES_PASSWORD: mlpass
          POSTGRES_DB: mathledger
        ports: [ "5432:5432" ]
        options: >-
          --health-cmd="pg_isready -U ml" --health-interval=10s
          --health-timeout=5s --health-retries=5
    env:
      DATABASE_URL: postgresql://ml:mlpass@localhost:5432/mathledger?connect_timeout=5
    steps:
      - name: Record job start
        id: start
        run: echo "start_time=$(date +%s)" >> $GITHUB_OUTPUT
      
      - uses: actions/checkout@v4
      - uses: astral-sh/setup-uv@v1
      
      - name: Cache uv dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/uv
          key: uv-${{ runner.os }}-${{ hashFiles('**/pyproject.toml') }}
          restore-keys: |
            uv-${{ runner.os }}-
      
      - run: uv sync
      
      - name: Unit tests with coverage (consolidated, optimized)
        run: |
          NO_NETWORK=true PYTHONPATH=$(pwd) uv run coverage run -m pytest -q \
            tests/test_canon.py \
            tests/test_mp.py \
            tests/test_subst.py \
            tests/test_taut.py \
            tests/devxp/test_branch_guard.py \
            tests/qa/test_metrics_lint_v1.py
          uv run coverage report --fail-under=70
      
      - name: Performance regression gate
        run: |
          if [ -f "tools/perf/check_regression.py" ]; then
            uv run python tools/perf/check_regression.py
          else
            echo "Performance regression check not available, skipping"
          fi
      
      - name: Record job timing
        if: always()
        run: |
          END_TIME=$(date +%s)
          DURATION=$((END_TIME - ${{ steps.start.outputs.start_time }}))
          mkdir -p artifacts/ci
          echo "{\"job\":\"test\",\"duration\":$DURATION,\"status\":\"${{ job.status }}\",\"timestamp\":\"$(date -u +%Y-%m-%dT%H:%M:%SZ)\"}" > artifacts/ci/test_timing.json
      
      - name: Upload timing data
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-timing
          path: artifacts/ci/test_timing.json
          retention-days: 30

  uplift-omega:
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/integrate/ledger-v0.1' || github.event_name == 'pull_request'
    steps:
      - name: Record job start
        id: start
        run: echo "start_time=$(date +%s)" >> $GITHUB_OUTPUT
      
      - uses: actions/checkout@v4
      - uses: astral-sh/setup-uv@v1
      
      - name: Cache uv dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/uv
          key: uv-${{ runner.os }}-${{ hashFiles('**/pyproject.toml') }}
          restore-keys: |
            uv-${{ runner.os }}-
      
      - run: uv sync
      
      - name: Create synthetic PL-2 test data
        run: |
          mkdir -p artifacts/wpv5
          cat > artifacts/wpv5/pl2_ab.csv << 'CSVEOF'
          mode,proofs_per_hour,block_root,policy_hash,wall_minutes,block_no,run_id
          pl2-baseline,120.00,a7064a9da087e1daa4df8978db4636cad47c963f7d9a55bfedfa9dd12ba4994c,,15.0000,2001,seed101-pl2-baseline
          pl2-baseline,120.00,0c44e8f7c3b2a1d5e9f6a8b4c7d2e5f8a1b4c7d2e5f8a1b4c7d2e5f8a196c1,,15.0000,2002,seed102-pl2-baseline
          pl2-baseline,128.00,d8ab7f2e5c8b1a4d7e0f3a6b9c2d5e8f1a4b7c0d3e6f9a2b5c8d1e4f7a10fe,,15.0000,2003,seed103-pl2-baseline
          pl2-guided,252.00,336c6e62fd0b5dbd9fb1f9fefd388d9edd4fbe904c9cc3b5cfbf392cad14862b,40aff2e9d2d8922e47afd4648e6967497158785fbd1da870e7110266bf944880,15.0000,2008,seed101-pl2-guided
          pl2-guided,264.00,c721f8e3a6b9c2d5e8f1a4b7c0d3e6f9a2b5c8d1e4f7a0b3c6d9e2f5a8b187c,40aff2e9d2d8922e47afd4648e6967497158785fbd1da870e7110266bf944880,15.0000,2009,seed102-pl2-guided
          pl2-guided,288.00,e7f6d2a5b8c1e4f7a0b3c6d9e2f5a8b1c4d7e0f3a6b9c2d5e8f1a4b7c0cac7,40aff2e9d2d8922e47afd4648e6967497158785fbd1da870e7110266bf944880,15.0000,2010,seed103-pl2-guided
          CSVEOF
      
      - name: Run Uplift Gate (optimized)
        run: |
          if [ -f "performance_passport.json" ]; then
            echo "Using existing performance passport"
          else
            echo "No performance passport found, using fallback"
          fi
          
          if [ -f "scripts/uplift_gate.py" ]; then
            uv run python scripts/uplift_gate.py \
              --fol-csv artifacts/wpv5/fol_ab.csv \
              --pl2-csv artifacts/wpv5/pl2_ab.csv \
              --passport-path performance_passport.json \
              --output-dir artifacts/badges
          else
            echo "Uplift gate not available, skipping"
            mkdir -p artifacts/badges
          fi
        continue-on-error: false
      
      - name: Record job timing
        if: always()
        run: |
          END_TIME=$(date +%s)
          DURATION=$((END_TIME - ${{ steps.start.outputs.start_time }}))
          mkdir -p artifacts/ci
          echo "{\"job\":\"uplift-omega\",\"duration\":$DURATION,\"status\":\"${{ job.status }}\",\"timestamp\":\"$(date -u +%Y-%m-%dT%H:%M:%SZ)\"}" > artifacts/ci/uplift_timing.json
      
      - name: Upload timing data
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: uplift-timing
          path: artifacts/ci/uplift_timing.json
          retention-days: 30
      
      - name: Upload badge artifacts
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: uplift-verified-badges-${{ github.run_number }}
          path: |
            artifacts/badges/*.json
            artifacts/badges/*.md
          retention-days: 30

  velocity-report:
    runs-on: ubuntu-latest
    needs: [test, uplift-omega]
    if: always()
    steps:
      - uses: actions/checkout@v4
      - uses: astral-sh/setup-uv@v1
      
      - name: Cache uv dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/uv
          key: uv-${{ runner.os }}-${{ hashFiles('**/pyproject.toml') }}
          restore-keys: |
            uv-${{ runner.os }}-
      
      - run: uv sync
      
      - name: Download timing artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: '*-timing'
          path: artifacts/ci/timings
          merge-multiple: true
      
      - name: Generate velocity report with RFC 8785 canonicalization
        run: |
          mkdir -p artifacts/ci artifacts/allblue
          
          # Aggregate timing data
          TOTAL_DURATION=0
          TEST_DURATION=0
          UPLIFT_DURATION=0
          
          if [ -f "artifacts/ci/timings/test_timing.json" ]; then
            TEST_DURATION=$(jq -r '.duration' artifacts/ci/timings/test_timing.json)
            TOTAL_DURATION=$((TOTAL_DURATION + TEST_DURATION))
          fi
          
          if [ -f "artifacts/ci/timings/uplift_timing.json" ]; then
            UPLIFT_DURATION=$(jq -r '.duration' artifacts/ci/timings/uplift_timing.json)
            TOTAL_DURATION=$((TOTAL_DURATION + UPLIFT_DURATION))
          fi
          
          # Calculate wall-clock time (max of parallel jobs)
          WALL_CLOCK_TIME=$TEST_DURATION
          if [ $UPLIFT_DURATION -gt $WALL_CLOCK_TIME ]; then
            WALL_CLOCK_TIME=$UPLIFT_DURATION
          fi
          
          # Calculate velocity improvement
          BASELINE=${{ env.CI_BASELINE_DURATION }}
          if [ $WALL_CLOCK_TIME -gt 0 ]; then
            IMPROVEMENT=$(echo "scale=1; (($BASELINE - $WALL_CLOCK_TIME) / $BASELINE) * 100" | bc)
          else
            IMPROVEMENT=0
          fi
          
          # Generate optimization hash (SHA256 of workflow config)
          WORKFLOW_CONFIG='{"caching":true,"parallel_jobs":["test","uplift-omega"],"optimization_level":2,"velocity_enabled":true}'
          OPT_HASH=$(echo -n "$WORKFLOW_CONFIG" | sha256sum | cut -d' ' -f1)
          
          # Generate canonical perf_log.json (RFC 8785 compliant)
          cat > artifacts/ci/perf_log.json << JSONEOF
          {
            "baseline_duration_seconds": $BASELINE,
            "generated_at": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
            "optimization_hash": "$OPT_HASH",
            "runs": [
              {
                "end_time": $(date +%s),
                "jobs": [
                  {
                    "duration_seconds": $TEST_DURATION,
                    "job_name": "test",
                    "start_time": $(date +%s),
                    "status": "${{ needs.test.result }}"
                  },
                  {
                    "duration_seconds": $UPLIFT_DURATION,
                    "job_name": "uplift-omega",
                    "start_time": $(date +%s),
                    "status": "${{ needs.uplift-omega.result }}"
                  }
                ],
                "run_id": "${{ github.run_id }}",
                "start_time": $(date +%s),
                "total_duration_seconds": $TOTAL_DURATION,
                "trigger": "${{ github.event_name }}",
                "velocity_improvement_percent": $IMPROVEMENT,
                "wall_clock_duration_seconds": $WALL_CLOCK_TIME,
                "workflow_name": "ci-velocity.yml"
              }
            ],
            "version": "1.0"
          }
          JSONEOF
          
          # Generate CI summary
          echo "## CI Velocity Report" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if (( $(echo "$IMPROVEMENT >= 0" | bc -l) )); then
            echo "[PASS] CI Velocity: ${IMPROVEMENT}% faster" >> $GITHUB_STEP_SUMMARY
          else
            echo "[REGRESSION] CI Velocity: ${IMPROVEMENT}% slower" >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "CI_OPTIMIZATION_HASH: $OPT_HASH" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Performance Metrics:**" >> $GITHUB_STEP_SUMMARY
          echo "- Wall-Clock Time: ${WALL_CLOCK_TIME}s" >> $GITHUB_STEP_SUMMARY
          echo "- Baseline: ${BASELINE}s" >> $GITHUB_STEP_SUMMARY
          echo "- Target: ${{ env.CI_TARGET_DURATION }}s (50% reduction)" >> $GITHUB_STEP_SUMMARY
          echo "- Test Job: ${TEST_DURATION}s" >> $GITHUB_STEP_SUMMARY
          echo "- Uplift Job: ${UPLIFT_DURATION}s" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Variance check (Proof-or-Abstain on >5%)
          TARGET_IMPROVEMENT=50.0
          VARIANCE=$(echo "scale=1; (($IMPROVEMENT - $TARGET_IMPROVEMENT) / $TARGET_IMPROVEMENT * 100)" | bc | tr -d '-')
          
          if (( $(echo "$VARIANCE > 5" | bc -l) )); then
            echo "**WARNING: Variance >5% detected. Abstaining from velocity claim.**" >> $GITHUB_STEP_SUMMARY
            echo "Expected: ~${TARGET_IMPROVEMENT}% improvement, Actual: ${IMPROVEMENT}%" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
          fi
          
          # Check if ALL BLUE (all jobs passed)
          TEST_STATUS="${{ needs.test.result }}"
          UPLIFT_STATUS="${{ needs.uplift-omega.result }}"
          
          if [ "$TEST_STATUS" = "success" ] && [ "$UPLIFT_STATUS" = "success" ]; then
            echo "**[PASS] ALL BLUE - All CI jobs passed**" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            
            # Create fleet_state.json archive
            cat > artifacts/allblue/fleet_state.json << FLEETEOF
          {
            "all_blue_timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
            "ci_optimization_hash": "$OPT_HASH",
            "github_ref": "${{ github.ref }}",
            "github_run_id": "${{ github.run_id }}",
            "github_sha": "${{ github.sha }}",
            "jobs": {
              "test": {
                "duration_seconds": $TEST_DURATION,
                "status": "$TEST_STATUS"
              },
              "uplift-omega": {
                "duration_seconds": $UPLIFT_DURATION,
                "status": "$UPLIFT_STATUS"
              }
            },
            "state_hash": "$(echo -n "${{ github.sha }}|$OPT_HASH|$(date +%s)" | sha256sum | cut -d' ' -f1)",
            "velocity_improvement_percent": $IMPROVEMENT,
            "wall_clock_duration_seconds": $WALL_CLOCK_TIME,
            "workflow": "ci-velocity.yml"
          }
          FLEETEOF
            
            echo "Fleet state archived to artifacts/allblue/fleet_state.json" >> $GITHUB_STEP_SUMMARY
            echo "State Hash: $(jq -r '.state_hash' artifacts/allblue/fleet_state.json)" >> $GITHUB_STEP_SUMMARY
          else
            echo "**CI Status: Not all jobs passed**" >> $GITHUB_STEP_SUMMARY
            echo "- Test: $TEST_STATUS" >> $GITHUB_STEP_SUMMARY
            echo "- Uplift: $UPLIFT_STATUS" >> $GITHUB_STEP_SUMMARY
          fi
      
      - name: Upload velocity report
        uses: actions/upload-artifact@v4
        with:
          name: velocity-report-${{ github.run_number }}
          path: |
            artifacts/ci/perf_log.json
            artifacts/allblue/fleet_state.json
          retention-days: 90
